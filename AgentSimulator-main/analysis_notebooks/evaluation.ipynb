{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.log.util import sorting\n",
    "from scipy.stats import wasserstein_distance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from log_distance_measures.config import EventLogIDs, AbsoluteTimestampType, discretize_to_hour\n",
    "from log_distance_measures.control_flow_log_distance import control_flow_log_distance\n",
    "from log_distance_measures.n_gram_distribution import n_gram_distribution_distance\n",
    "from log_distance_measures.absolute_event_distribution import absolute_event_distribution_distance\n",
    "from log_distance_measures.case_arrival_distribution import case_arrival_distribution_distance\n",
    "from log_distance_measures.circadian_event_distribution import circadian_event_distribution_distance\n",
    "from log_distance_measures.relative_event_distribution import relative_event_distribution_distance\n",
    "from log_distance_measures.work_in_progress import work_in_progress_distance\n",
    "from log_distance_measures.cycle_time_distribution import cycle_time_distribution_distance\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_first_float(cell):\n",
    "    if isinstance(cell, str):\n",
    "        # Use regular expression to extract the first float and the value in brackets\n",
    "        match = re.match(r'(\\d+\\.\\d+)(?: \\((\\d+\\.\\d+)\\))?', cell)\n",
    "        if match:\n",
    "            return float(match.group(1)), (match.group(2)) if match.group(2) else ''\n",
    "        else:\n",
    "            return float('inf'), ''\n",
    "    else:\n",
    "        return cell, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_min_max(s):\n",
    "    \"\"\"\n",
    "    Highlight the minimum value in green and the maximum value in red for each column.\n",
    "    \"\"\"\n",
    "    is_min = s == s.min()\n",
    "    is_max = s == s.max()\n",
    "    min_max_style = ['background-color: green' if v else '' for v in is_min]\n",
    "    for i, v in enumerate(is_max):\n",
    "        if v:\n",
    "            min_max_style[i] = 'background-color: red'\n",
    "    return min_max_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_column_names(df):\n",
    "    if 'case:concept:name' in df.columns:\n",
    "        df = df.rename(columns={'case:concept:name': 'case_id'})\n",
    "    elif 'caseid' in df.columns:\n",
    "        df = df.rename(columns={'caseid': 'case_id'})\n",
    "    if 'Activity' in df.columns:\n",
    "        df = df.rename(columns={'Activity': 'activity'})\n",
    "    elif 'activity_name' in df.columns:\n",
    "        df = df.rename(columns={'activity_name': 'activity'})\n",
    "    elif 'task' in df.columns:\n",
    "        df = df.rename(columns={'task': 'activity'})\n",
    "    elif 'concept:name' in df.columns:\n",
    "        df = df.rename(columns={'concept:name': 'activity'})\n",
    "    if 'Resource' in df.columns:\n",
    "        df = df.rename(columns={'Resource': 'resource'})\n",
    "    elif 'user' in df.columns:\n",
    "        df = df.rename(columns={'user': 'resource'})\n",
    "    elif 'agent' in df.columns:\n",
    "        if 'resource' in df.columns:\n",
    "            df = df.drop(['resource'], axis=1)\n",
    "        df = df.rename(columns={'agent': 'resource'})\n",
    "    elif 'org:resource' in df.columns:\n",
    "        df = df.rename(columns={'org:resource': 'resource'})\n",
    "    if 'start_timestamp' in df.columns:\n",
    "        df = df.rename(columns={'start_timestamp': 'start_time'})\n",
    "    if 'end_timestamp' in df.columns:\n",
    "        df = df.rename(columns={'end_timestamp': 'end_time'})\n",
    "    # for SIMOD simulated logs\n",
    "    if 'start_time' in df.columns:\n",
    "        df = df.rename(columns={'start_time': 'start_time'})\n",
    "    if 'end_time' in df.columns:\n",
    "        df = df.rename(columns={'end_time': 'end_time'})\n",
    "    if 'start:timestamp' in df.columns:\n",
    "        df = df.rename(columns={'start:timestamp': 'start_time'})\n",
    "    if 'time:timestamp' in df.columns:\n",
    "        df = df.rename(columns={'time:timestamp': 'end_time'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_(log_paths, name_experiments):\n",
    "    def perform_evauluation(all_metrics, PATH_SIMULATED_LOG, test_log):\n",
    "        for i in range(10):\n",
    "            # print(f\"Evaluate simulation {i}\")\n",
    "            path_simulated_file = PATH_SIMULATED_LOG + '/simulated_log_' + str(i) + '.csv'\n",
    "            # read simulated log and align column names\n",
    "            simulated_log = pd.read_csv(path_simulated_file)\n",
    "            simulated_log = align_column_names(simulated_log)\n",
    "            # print(simulated_log)\n",
    "            # print(\"########\")\n",
    "            # print(simulated_log[event_log_ids.activity].unique())\n",
    "            simulated_log[event_log_ids.start_time] = pd.to_datetime(simulated_log[event_log_ids.start_time], utc=True, format='mixed')\n",
    "            simulated_log[event_log_ids.end_time] = pd.to_datetime(simulated_log[event_log_ids.end_time], utc=True, format='mixed')\n",
    "\n",
    "            # Call passing the event logs, and its column ID mappings\n",
    "            ngd = n_gram_distribution_distance(test_log, event_log_ids, simulated_log, event_log_ids, n=3)\n",
    "            all_metrics['NGD'].append(ngd)\n",
    "\n",
    "            # Call passing the event logs, its column ID mappings, timestamp type, and discretize function\n",
    "            aedd = absolute_event_distribution_distance(\n",
    "                test_log, event_log_ids,  # First event log and its column id mappings\n",
    "                simulated_log, event_log_ids,  # Second event log and its column id mappings\n",
    "                discretize_type=AbsoluteTimestampType.BOTH,  # Type of timestamp distribution (consider start times and/or end times)\n",
    "                discretize_event=discretize_to_hour  # Function to discretize the absolute seconds of each timestamp (default by hour)\n",
    "            )\n",
    "            all_metrics['AEDD'].append(aedd)\n",
    "\n",
    "            # cadd = case_arrival_distribution_distance(\n",
    "            #     test_log, event_log_ids,  # First event log and its column id mappings\n",
    "            #     simulated_log, event_log_ids,  # Second event log and its column id mappings\n",
    "            #     discretize_event=discretize_to_hour  # Function to discretize each timestamp (default by hour)\n",
    "            # )\n",
    "            # all_metrics['CADD'].append(cadd)\n",
    "\n",
    "            cedd = circadian_event_distribution_distance(\n",
    "                test_log, event_log_ids,  # First event log and its column id mappings\n",
    "                simulated_log, event_log_ids,  # Second event log and its column id mappings\n",
    "                discretize_type=AbsoluteTimestampType.BOTH  # Consider both start/end timestamps of each activity instance\n",
    "            )\n",
    "            all_metrics['CEDD'].append(cedd)\n",
    "\n",
    "            redd = relative_event_distribution_distance(\n",
    "                test_log, event_log_ids,  # First event log and its column id mappings\n",
    "                simulated_log, event_log_ids,  # Second event log and its column id mappings\n",
    "                discretize_type=AbsoluteTimestampType.BOTH,  # Type of timestamp distribution (consider start times and/or end times)\n",
    "                discretize_event=discretize_to_hour  # Function to discretize the absolute seconds of each timestamp (default by hour)\n",
    "            )\n",
    "            all_metrics['REDD'].append(redd)\n",
    "\n",
    "\n",
    "            ctdd = cycle_time_distribution_distance(\n",
    "                test_log, event_log_ids,  # First event log and its column id mappings\n",
    "                simulated_log, event_log_ids,  # Second event log and its column id mappings\n",
    "                bin_size=pd.Timedelta(hours=1)  # Bins of 1 hour\n",
    "            )\n",
    "            all_metrics['CTDD'].append(ctdd)\n",
    "\n",
    "        return all_metrics\n",
    "    \n",
    "    number_evaluations = len(log_paths)\n",
    "\n",
    "    # Set event log column ID mapping\n",
    "    event_log_ids = EventLogIDs(  # These values are stored in DEFAULT_CSV_IDS\n",
    "        case=\"case_id\",\n",
    "        activity=\"activity\",\n",
    "        start_time=\"start_time\",\n",
    "        end_time=\"end_time\",\n",
    "        resource='resource'\n",
    "    )\n",
    "\n",
    "    index_names = name_experiments\n",
    "    results_df = pd.DataFrame(index=index_names)\n",
    "    mean_results = pd.DataFrame(index=index_names)\n",
    "\n",
    "    for experiment in range(number_evaluations):\n",
    "        # Read and transform time attributes\n",
    "        test_log = pd.read_csv(log_paths[experiment][0])\n",
    "        test_log = align_column_names(test_log)\n",
    "        test_log[event_log_ids.start_time] = pd.to_datetime(test_log[event_log_ids.start_time], utc=True, format='mixed')\n",
    "        test_log[event_log_ids.end_time] = pd.to_datetime(test_log[event_log_ids.end_time], utc=True, format='mixed')\n",
    "\n",
    "        PATH_SIMULATED_LOG = log_paths[experiment][1]\n",
    "\n",
    "        all_metrics = {\n",
    "            'NGD': [],\n",
    "            'AEDD': [],\n",
    "            # 'CADD': [],\n",
    "            'CEDD': [],\n",
    "            'REDD': [],\n",
    "            'CTDD': [],\n",
    "        }\n",
    "\n",
    "        all_metrics = perform_evauluation(all_metrics, PATH_SIMULATED_LOG, test_log)\n",
    "\n",
    "        mean_results.loc[index_names[experiment], 'N-Gram Distribution Distance'] = round(np.mean(all_metrics['NGD']), 3)\n",
    "        mean_results.loc[index_names[experiment], 'Absolute Event Distribution Distance'] = round(np.mean(all_metrics['AEDD']), 3)\n",
    "        # mean_results.loc[index_names[experiment], 'Case Arrival Distribution Distance'] = round(np.mean(all_metrics['CADD']), 3)\n",
    "        mean_results.loc[index_names[experiment], 'Circadian Event Distribution Distance'] = round(np.mean(all_metrics['CEDD']), 3)\n",
    "        mean_results.loc[index_names[experiment], 'Relative Event Distribution Distance'] = round(np.mean(all_metrics['REDD']), 3)\n",
    "        mean_results.loc[index_names[experiment], 'Cycle Time Distribution Distance'] = round(np.mean(all_metrics['CTDD']), 3)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        results_df.loc[index_names[experiment], 'N-Gram Distribution Distance'] = f\"{round(np.mean(all_metrics['NGD']), 3)} ({round(np.std(all_metrics['NGD']), 3)})\"\n",
    "        results_df.loc[index_names[experiment], 'Absolute Event Distribution Distance'] = f\"{round(np.mean(all_metrics['AEDD']), 3)} ({round(np.std(all_metrics['AEDD']), 3)})\"\n",
    "        # results_df.loc[index_names[experiment], 'Case Arrival Distribution Distance'] = f\"{round(np.mean(all_metrics['CADD']), 3)} ({round(np.std(all_metrics['CADD']), 3)})\"\n",
    "        results_df.loc[index_names[experiment], 'Circadian Event Distribution Distance'] = f\"{round(np.mean(all_metrics['CEDD']), 3)} ({round(np.std(all_metrics['CEDD']), 3)})\"\n",
    "        results_df.loc[index_names[experiment], 'Relative Event Distribution Distance'] = f\"{round(np.mean(all_metrics['REDD']), 3)} ({round(np.std(all_metrics['REDD']), 3)})\"\n",
    "        results_df.loc[index_names[experiment], 'Cycle Time Distribution Distance'] = f\"{round(np.mean(all_metrics['CTDD']), 3)} ({round(np.std(all_metrics['CTDD']), 3)})\"\n",
    "\n",
    "    return mean_results, results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-Gram Distribution Distance</th>\n",
       "      <th>Absolute Event Distribution Distance</th>\n",
       "      <th>Circadian Event Distribution Distance</th>\n",
       "      <th>Relative Event Distribution Distance</th>\n",
       "      <th>Cycle Time Distribution Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AgentSim</th>\n",
       "      <td>0.075 (0.021)</td>\n",
       "      <td>3.007 (0.609)</td>\n",
       "      <td>0.219 (0.033)</td>\n",
       "      <td>1.569 (0.614)</td>\n",
       "      <td>1.703 (0.786)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         N-Gram Distribution Distance Absolute Event Distribution Distance  \\\n",
       "AgentSim                0.075 (0.021)                        3.007 (0.609)   \n",
       "\n",
       "         Circadian Event Distribution Distance  \\\n",
       "AgentSim                         0.219 (0.033)   \n",
       "\n",
       "         Relative Event Distribution Distance Cycle Time Distribution Distance  \n",
       "AgentSim                        1.569 (0.614)                    1.703 (0.786)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TEST_LOG_MAS = '../simulated_data/LoanApp.csv/main_results/test_preprocessed.csv'\n",
    "PATH_SIMULATED_LOG_MAS = '../simulated_data/LoanApp.csv/main_results'\n",
    "\n",
    "log_paths = [\n",
    "    [PATH_TEST_LOG_MAS, PATH_SIMULATED_LOG_MAS],\n",
    "]\n",
    "\n",
    "name_experiments = ['AgentSim']\n",
    "\n",
    "mean_results, results_df = main_(log_paths, name_experiments)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-Gram Distribution Distance</th>\n",
       "      <th>Absolute Event Distribution Distance</th>\n",
       "      <th>Circadian Event Distribution Distance</th>\n",
       "      <th>Relative Event Distribution Distance</th>\n",
       "      <th>Cycle Time Distribution Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AgentSim</th>\n",
       "      <td>0.264 (0.009)</td>\n",
       "      <td>143.402 (2.97)</td>\n",
       "      <td>1.835 (0.109)</td>\n",
       "      <td>14.159 (2.767)</td>\n",
       "      <td>25.105 (3.442)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         N-Gram Distribution Distance Absolute Event Distribution Distance  \\\n",
       "AgentSim                0.264 (0.009)                       143.402 (2.97)   \n",
       "\n",
       "         Circadian Event Distribution Distance  \\\n",
       "AgentSim                         1.835 (0.109)   \n",
       "\n",
       "         Relative Event Distribution Distance Cycle Time Distribution Distance  \n",
       "AgentSim                       14.159 (2.767)                   25.105 (3.442)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TEST_LOG_MAS = '../simulated_data/Confidential_1000/main_results/test_preprocessed.csv'\n",
    "PATH_SIMULATED_LOG_MAS = '../simulated_data/Confidential_1000/main_results'\n",
    "\n",
    "log_paths = [\n",
    "    [PATH_TEST_LOG_MAS, PATH_SIMULATED_LOG_MAS],\n",
    "]\n",
    "\n",
    "name_experiments = ['AgentSim']\n",
    "\n",
    "mean_results, results_df = main_(log_paths, name_experiments)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
