{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.eventlog_utils import convert_log\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from log_distance_measures.config import EventLogIDs, AbsoluteTimestampType, discretize_to_hour\n",
    "from log_distance_measures.control_flow_log_distance import control_flow_log_distance\n",
    "from log_distance_measures.n_gram_distribution import n_gram_distribution_distance\n",
    "from log_distance_measures.absolute_event_distribution import absolute_event_distribution_distance\n",
    "from log_distance_measures.case_arrival_distribution import case_arrival_distribution_distance\n",
    "from log_distance_measures.circadian_event_distribution import circadian_event_distribution_distance\n",
    "from log_distance_measures.relative_event_distribution import relative_event_distribution_distance\n",
    "from log_distance_measures.work_in_progress import work_in_progress_distance\n",
    "from log_distance_measures.cycle_time_distribution import cycle_time_distribution_distance\n",
    "from log_distance_measures import earth_movers_distance\n",
    "from src.res_based_ced import resource_based_circadian_event_distribution_distance\n",
    "from distance_utils import emd_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_studies = {\n",
    "    1: 'Purchasing',\n",
    "    2: 'Production',\n",
    "    3: 'Consulta',\n",
    "    4: 'bpi12',\n",
    "    5: 'bpi17',\n",
    "    6: 'sepsis',\n",
    "    7: 'rtf',\n",
    "    8: 'bpi19'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case study: bpi17, our approach = False\n"
     ]
    }
   ],
   "source": [
    "# chose case study\n",
    "case_study = case_studies[5]\n",
    "\n",
    "# Choose if our approach or Sota\n",
    "our_approach = False\n",
    "Sota = not(our_approach)\n",
    "approach = 'SIMOD' if Sota else None\n",
    "print(f'Case study: {case_study}, our approach = {our_approach}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0741de6acd9b4fc0be348d2f978c38a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/5771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported log from Sota, approach: SIMOD\n",
      "imported log from Sota, approach: SIMOD ,columns renamed\n"
     ]
    }
   ],
   "source": [
    "log_real = xes_importer.apply(f'data/{case_study}/logTest.xes')\n",
    "log_real = pm4py.convert_to_dataframe(log_real)\n",
    "\n",
    "if our_approach:\n",
    "    log_sim = pd.read_csv(f'simulations/{case_study}/sim_0.csv')\n",
    "    print('imported log from our approach')\n",
    "\n",
    "elif Sota:\n",
    "    \n",
    "    if approach == 'RIMS':\n",
    "        log_sim = pd.read_csv(f'RIMS/{case_study}/results/rims/sim.csv')\n",
    "        del log_sim['st_wip']\n",
    "        del log_sim['queue']\n",
    "        del log_sim['st_tsk_wip']\n",
    "        print('imported log from Sota, approach:', approach)        \n",
    "    \n",
    "    elif approach == 'AgentSimulator':\n",
    "        log_sim = pd.read_csv(f'AgentSimulator/{case_study}/main_results/sim.csv')\n",
    "        print('imported log from Sota, approach:', approach)    \n",
    "\n",
    "    elif approach == 'SIMOD':\n",
    "        log_sim = pd.read_csv(f'SIMOD_TEST/{case_study}/output/best_result/evaluation/simulated_log_0.csv')\n",
    "        print('imported log from Sota, approach:', approach)\n",
    "\n",
    "    elif approach == 'DSIM':\n",
    "        log_sim = pd.read_csv(f'DSIM/results/generated_logs/{case_study}/DSIM/sim.csv')\n",
    "        print('imported log from Sota, approach:', approach)\n",
    "\n",
    "    else:\n",
    "        log_sim = pd.read_csv(f'Sota/{case_study}/{approach}/sim.csv')\n",
    "    \n",
    "    #Rename the columns named 'end_timestamp' and 'start_timestamp' with 'time:timestamp' and 'start:timestamp'\n",
    "    log_sim = log_sim.rename(columns={'end_timestamp': 'time:timestamp', \n",
    "                                      'start_timestamp': 'start:timestamp', \n",
    "                                      'task':'concept:name',\n",
    "                                      'caseid': 'case:concept:name',\n",
    "                                      'resource': 'org:resource'}, errors='ignore')\n",
    "    \n",
    "    # Errors='ignore' has been set because the log from francesca meneghello et al has some columns already correctly\n",
    "\n",
    "    print('imported log from Sota, approach:', approach, ',columns renamed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5771/5771 [01:11<00:00, 80.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert event log format lifecycles\n",
    "if 'lifecycle:transition' in log_real.columns:\n",
    "    log_real = convert_log(log_real)\n",
    "    log_real.rename(columns={'START': 'start:timestamp', 'END': 'time:timestamp'}, errors='ignore', inplace=True)\n",
    "    log_real.reset_index(inplace=True)\n",
    "if 'lifecycle:transition' in log_sim.columns:\n",
    "    log_sim = convert_log(log_sim)\n",
    "    log_sim.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set event log column ID mapping\n",
    "event_log_ids = EventLogIDs(\n",
    "    case=\"case:concept:name\",\n",
    "    activity=\"concept:name\",\n",
    "    start_time=\"start:timestamp\",\n",
    "    end_time=\"time:timestamp\",\n",
    "    resource=\"org:resource\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_real[event_log_ids.start_time] = pd.to_datetime(log_real[event_log_ids.start_time], utc=True)\n",
    "log_real[event_log_ids.end_time] = pd.to_datetime(log_real[event_log_ids.end_time], utc=True)\n",
    "\n",
    "# log_sim[event_log_ids.start_time] = [i[:19] for i in log_sim[event_log_ids.start_time].values]\n",
    "# log_sim[event_log_ids.end_time] = [i[:19] for i in log_sim[event_log_ids.end_time].values]\n",
    "# log_sim[event_log_ids.start_time] = pd.to_datetime(log_sim[event_log_ids.start_time], utc=True)\n",
    "# log_sim[event_log_ids.end_time] = pd.to_datetime(log_sim[event_log_ids.end_time], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize distances dictionary\n",
    "distances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from log_distance_measures.circadian_workforce_distribution import circadian_workforce_distribution_distance\n",
    "print('case study is: ', case_study, 'CWD is: ', circadian_workforce_distribution_distance(log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generateed Attributes Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attr distance:  nan\n"
     ]
    }
   ],
   "source": [
    "distance = emd_attributes(log_real, log_sim, attr_names=[])\n",
    "print('Attr distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['emd_attributes'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WARNING: It may take a long time</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control-flow Log Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call passing the event logs, and its column ID mappings\n",
    "distance = control_flow_log_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CF Log distance: ', distance)\n",
    "\n",
    "# Fill the distances dictionary\n",
    "distances['control_flow_log_distance'] = distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call passing the event logs, and its column ID mappings\n",
    "distance = n_gram_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    n=n_gram\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N-Gram distr. distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['n_gram_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Event Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMD of the (END) timestamps distribution where each bin represents a minute\n",
    "distance = absolute_event_distribution_distance(\n",
    "    log_real, event_log_ids,\n",
    "    log_sim, event_log_ids,\n",
    "    discretize_type=AbsoluteTimestampType.END,\n",
    "    discretize_event=discretize_to_hour\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Absolute Event Distribution Distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['absolute_event_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Arrival Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = case_arrival_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    discretize_event=discretize_to_hour  # Function to discretize each timestamp (default by hour)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Case Arrival distr distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['case_arrival_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circadian Event Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = circadian_event_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    discretize_type=AbsoluteTimestampType.BOTH  # Consider both start/end timestamps of each activity instance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Circadian Event distr distance: ', distance)\n",
    "# Fill the distances dictionary \n",
    "distances['circadian_event_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource-Based Circadian Event Distribution Distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = resource_based_circadian_event_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    discretize_type=AbsoluteTimestampType.BOTH  # Consider both start/end timestamps of each activity instance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resource-Based Circadian Event distr distance: ', distance)\n",
    "# Fill the distances dictionary \n",
    "distances['resource_based_circadian_event_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Event Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call passing the event logs, its column ID mappings, timestamp type, and discretize function\n",
    "distance = relative_event_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    discretize_type=AbsoluteTimestampType.BOTH,  # Type of timestamp distribution (consider start times and/or end times)\n",
    "    discretize_event=discretize_to_hour  # Function to discretize the absolute seconds of each timestamp (default by hour)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relative Event distr distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['relative_event_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work in Progress Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>WARNING: It may take a long time</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call passing the event logs, its column ID mappings, timestamp type, and discretize function\n",
    "# distance = work_in_progress_distance(\n",
    "#     log_real, event_log_ids,  # First event log and its column id mappings\n",
    "#     log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "#     window_size=pd.Timedelta(hours=1)  # Bins of 1 hour\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Work in Progress distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "# distances['work_in_progress_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle Time Distribution Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = cycle_time_distribution_distance(\n",
    "    log_real, event_log_ids,  # First event log and its column id mappings\n",
    "    log_sim, event_log_ids,  # Second event log and its column id mappings\n",
    "    bin_size=pd.Timedelta(hours=1)  # Bins of 1 minute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cycle Time distr distance: ', distance)\n",
    "# Fill the distances dictionary\n",
    "distances['cycle_time_distribution_distance'] = distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'case study is {case_study} for approach {approach}, with our approach {our_approach} and Sota {Sota}')\n",
    "# Save the distances dictionary to a file with pkl\n",
    "pd.to_pickle(distances, f'simulations/{case_study}/metrics.pkl')\n",
    "\n",
    "# Print the distances vector with each distance measure, in different lines\n",
    "for key, value in distances.items():\n",
    "    print(key, value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast them into .xes for evaluating entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf283d9e78294fc0a98ff280e9848f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Purchasing log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        6.477  \n",
      " The number of traces is 122\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        5.626  \n",
      " The number of traces is 122\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :        8.983  \n",
      " The number of prefixes is 3760\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :         8.63  \n",
      " The number of prefixes is 3760\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f654855c1144eab6490d91e275fc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Production log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        7.481  \n",
      " The number of traces is 45\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        5.447  \n",
      " The number of traces is 45\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :       12.608  \n",
      " The number of prefixes is 2484\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :       11.112  \n",
      " The number of prefixes is 2484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd46b8dff37d4bb2aaad0eded8fcbc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/191 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Consulta log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        8.019  \n",
      " The number of traces is 191\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        7.395  \n",
      " The number of traces is 191\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :        9.184  \n",
      " The number of prefixes is 2923\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :        9.255  \n",
      " The number of prefixes is 2923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551236d7d4fd4d15963f5b1dfc92ec49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/1610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted bpi12 log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        7.234  \n",
      " The number of traces is 1610\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        6.827  \n",
      " The number of traces is 1610\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :        9.664  \n",
      " The number of prefixes is 20560\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :        9.339  \n",
      " The number of prefixes is 20560\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea13c9bff0bd494b8029737b02a10cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/5771 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted bpi17 log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        9.529  \n",
      " The number of traces is 5771\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        8.982  \n",
      " The number of traces is 5771\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :       10.434  \n",
      " The number of prefixes is 91805\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :       10.226  \n",
      " The number of prefixes is 91805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc232947af543159b5608c6af7cbba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted sepsis log to XES format\n",
      "Real - Trace  The number of traces is 210\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        7.535  \n",
      " The number of traces is 210\n",
      "Real - Prefix  The number of prefixes is 2983\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :        9.378  \n",
      " The number of prefixes is 2983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3257baf43448278bd31e83682ad4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/30074 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted rtf log to XES format\n",
      "Real - Trace  The number of traces is 30074\n",
      "Gen - Trace  The number of traces is 30074\n",
      "Real - Prefix  The number of prefixes is 113831\n",
      "Gen - Prefix  The number of prefixes is 113831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ef847acb744e41a0e6cf0304c6eebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "exporting log, completed traces ::   0%|          | 0/13437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted bpi19 log to XES format\n",
      "Real - Trace \n",
      "~/logTrain.xes | Trace entropy    :        5.993  \n",
      " The number of traces is 13437\n",
      "Gen - Trace \n",
      "~/sim_0.xes | Trace entropy    :        6.072  \n",
      " The number of traces is 13437\n",
      "Real - Prefix \n",
      "~/logTrain.xes | Prefix based entropy :        7.837  \n",
      " The number of prefixes is 69317\n",
      "Gen - Prefix \n",
      "~/sim_0.xes | Prefix based entropy :        7.606  \n",
      " The number of prefixes is 69317\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import pm4py\n",
    "\n",
    "merge = False\n",
    "\n",
    "for case_study in case_studies.values():\n",
    "\n",
    "    if not merge:\n",
    "        # Import the .csv\n",
    "        log = pd.read_csv(f'simulations/{case_study}/sim_0.csv')\n",
    "        pref_num = len(log)\n",
    "        log['time:timestamp'] = pd.to_datetime(log['time:timestamp'])\n",
    "        log['case:concept:name'] = log['case:concept:name'].astype(str)\n",
    "        log = pm4py.convert_to_event_log(log)\n",
    "        # log_real = pm4py.read_xes(f'data/{case_study}/logTrain.xes')\n",
    "    \n",
    "    else:\n",
    "        log = pm4py.read_xes(f'data/{case_study}/logTrain.xes')\n",
    "        #convert the log to a dataframe\n",
    "        train_original = pm4py.convert_to_dataframe(train_original)\n",
    "        train_original = train_original[log.columns]  # Ensure the columns match\n",
    "\n",
    "        # Merge the two logs\n",
    "        log = pd.concat([train_original, log], ignore_index=True)\n",
    "\n",
    "    # Save it\n",
    "    pm4py.write_xes(log, f'simulations/{case_study}/sim_0.xes')\n",
    "\n",
    "    print(f'Converted {case_study} log to XES format')\n",
    "\n",
    "    result = subprocess.run(f'java -jar /home/padela/Scrivania/eventropy/eventropy.jar -f /home/padela/Scrivania/ProbabilityBasedEventLogGenerator/data/{case_study}/logTrain.xes',\n",
    "                             shell=True, capture_output=True, text=True)\n",
    "    print(f\"Real - Trace\", result.stdout, f'The number of traces is {len(log)}')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    result = subprocess.run(f'java -jar /home/padela/Scrivania/eventropy/eventropy.jar -f /home/padela/Scrivania/ProbabilityBasedEventLogGenerator/simulations/{case_study}/sim_0.xes',\n",
    "                             shell=True, capture_output=True, text=True)\n",
    "    print(f\"Gen - Trace\", result.stdout, f'The number of traces is {len(log)}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    result = subprocess.run(f'java -jar /home/padela/Scrivania/eventropy/eventropy.jar -p /home/padela/Scrivania/ProbabilityBasedEventLogGenerator/data/{case_study}/logTrain.xes',\n",
    "                             shell=True, capture_output=True, text=True)\n",
    "    print(f\"Real - Prefix\", result.stdout, f'The number of prefixes is {pref_num}')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    result = subprocess.run(f'java -jar /home/padela/Scrivania/eventropy/eventropy.jar -p /home/padela/Scrivania/ProbabilityBasedEventLogGenerator/simulations/{case_study}/sim_0.xes',\n",
    "                             shell=True, capture_output=True, text=True)\n",
    "    print(f\"Gen - Prefix\", result.stdout, f'The number of prefixes is {pref_num}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Purchasing',\n",
       " 2: 'Production',\n",
       " 3: 'Consulta',\n",
       " 4: 'bpi12',\n",
       " 5: 'bpi17',\n",
       " 6: 'sepsis',\n",
       " 7: 'rtf',\n",
       " 8: 'bpi19'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_studies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
